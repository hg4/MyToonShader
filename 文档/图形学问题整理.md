

\1. PBR的AO项 

美术烘的表示物体本身的光照死角，SSAO是物体之间太近造成死角。

 \2. SSAO实现与具体是怎么用的 

屏幕空间的每个像素做一个单位球然后随机撒点，看这些点有没有被屏幕中其他深度遮挡住，遮挡的越多ao值越大。

 \3. 延迟渲染原理与实现 

depthprepass + gbuffer+光照计算

 \4. 延迟渲染存的位置信息精度问题，为啥不直接用深度来还原世界空间的位置 、

？

 \5. 延迟渲染存的法线在哪个空间 

哪个都行，好像说观察空间存可以省一点

 \6. 延迟渲染怎么用AO 

不是照样用吗ssao只需要深度法线图就能做和延迟渲染不是刚好一起用。

 \7. 延迟渲染和前向渲染采样深度图的性能对比 

？

 \8. AO可以用直接光做吗 

不行啊ao假设radiance都是1啊。

 \9. PBR的间接光是怎么做的（IBL），IBL的漫反射部分怎么实现与采样的，优化是用什么（球谐），镜面反射部分是怎么实现的，有更快的方法来做镜面反射部分吗 
 \10. 用球谐的漏光问题 
 \11. G-buffer用了几个RT，格式是什么，深度图和颜色图采样器的区别是什么 

采样器 = 纹理过滤模式(point,bilinear,)+uv寻址方式（repeat，clamp，mirror.etc)

深度图

 \12. OpenGL纹理三种过滤方式 

nearest最近邻过滤、bilinear双线性插值、各向异性过滤(纹理长宽压缩不等比)

 \13. 各向异性过滤，有缺点吗 

存储开销大，解决不了对应关系是斜着的，只能解决长方形。

 \14. Mipmap层级的确定 

mipmap的意义是快速进行区域查询得到平均值。lod值自动计算大致是根据uv的偏导来计算的，相邻的uv差越大，代表纹理在屏幕中占的区域越小，lod值越大。顶点着色器中不能用tex2D因为还没光栅化计算不了uv偏导。

```glsl
tex2D(sampler2D tex, float2 uv)
{
	float dx=ddx(uv);
	float dy=ddy(uv);
	// texSize.xy为纹理tex的纹素大小
	// texSize.xy=1.0/float2(texWidth,texHeight)
    float px = texSize.x * dx;
    float py = texSize.y * dy;
    float lod = 0.5 * log2(max(dot(px, px), dot(py, py)));
    uv.w= lod;
    return tex2Dlod(tex, uv);
}

```

 \15. urp前向渲染的各个pass是怎么组织的，比如上一个pass的输出怎么当做下一个pass的输入 



\16. bilt的原理是啥 

画一个长方形。

 \17. 如果一个深度图已经被绑定到attachment上了，下一个pass该怎么去取这个深度图

把这个深度attachment copy到一个temporaryRT上。 
 \18. 基本的shadow map，以及PCF的filtersize是怎么确定的（PCSS） 
 \19. CSM的原理，在unity里实现的时候用了几级，是每帧更新吗？动态物体的阴影是怎么做的 
 \20. 光源剔除怎么实现的 

距离衰减，影响过小就剔除



openGL相关：

opengl图形API在做什么？draw call前CPU端的准备，如资源申请状态设置等。

相关的资源：缓冲对象（VBO、VAO、EBO、FBO）、shader、texture。

总的说来的逻辑就是申请分配一个ID，给ID对应的东西开内存，设置相关状态，传入数据，传到GPU。

VBO = 顶点数据

VAO = 顶点数据 + 对数据的解释和状态设置 + （EBO）

EBO = 用index buffer描述三角形，避免VAO中顶点重复（但有时候就需要重复）。

相机矩阵构建：

viewMatrix：由欧拉角可以计算相机前向量，前向量+世界上方向可以计算出旋转矩阵的3x3 matrix，加上相机位置得到平移矩阵，对RT矩阵求逆，就是viewMatrix。所以viewMatrix其实就是相机model matrix的逆矩阵。

projectionMatrix:  由near、far、fov、长宽比aspect可构建。也可以按将平截头体用矩阵映射到长方体，再按正交投影处理。

几何着色器：

输入是CPU端设定的图元（point、line、triangle .etc），输出是自己想要的图元，在几何着色器里对顶点做计算填充输出的图元。例如基于几何着色器的内轮廓线检测，先对mesh预处理组织成一个三角形+3个邻接三角形的顶点的形式输入到几何着色器，检测邻接面法线的夹角判断是否是内轮廓，如果是将计算一个刚好覆盖交界边的小四边形作为输出图元。



减少draw call相关：

GPU实例化：减轻draw call，对同样mesh同样材质的对象一次性发到GPU

静态批处理：减少draw call，将标明为static的多个相同材质球物体合批组成一个大物体一起发送到GPU中，缺点是这样做可能会破坏early-Z

动态批处理：对视野中使用相同材质球的一些物体动态的在一个draw call里完成。在进行场景绘制之前将所有的共享同一材质的模型的顶点信息变换到世界空间中，然后通过一次Draw call绘制多个模型，达到合批的目的。

SRP batcher：不减少draw call，但是能提高CPU端数据准备的效率。



overdraw相关：

后处理overdraw严重。减少overdraw方法：半透明从远到近混合overdraw很厉害，尽可能避免。对于不透明物体尽可能让他们从近到远渲染。pre-depth-pass和early-z都能减少overdraw。



伽马矫正：

sRGB->linear 乘2.2次方 linear->sRGB 开2.2次方

法线贴图：

切向量计算：用三角形顶点和uv可以计算切向量。

切线空间转对象空间：直接乘TBN矩阵。

对象空间转切线空间：乘TBN逆矩阵。

视差贴图：类似于一张高度偏移贴图，用这张图做出凹凸感。



如何渲染一个半透明物体：

先渲染不透明物体，再关闭zwrite开启ztest从远到近渲染不透明物体，不透明物从远到近按over操作叠加。

如果说要在已经画好的半透明物体上渲染不透明物体，可以用under操作。

![preview](https://pic4.zhimg.com/v2-9549ddbc09a020dbbe6c4dd4795cdd73_r.jpg)

如何解决一个大透明物体和一堆小透明物体后一起渲染造成的顺序错位问题？

因为大透明物体横跨的深度很大，可能一部分比小透明物体小，一部分比他们大，但是不透明渲染顺序是按物体排的不是按面片的，就会导致有可能小透明物体明明应该在前面但被大透明物体遮挡住的情况，本质原因是半透明排序无法处理半透明交叠的情况。最暴力的解决方案就是把大透明物体打散再排序。

environment lighting与GI

都是间接光照的一种，环境光照指的是对天空盒环境的光照反映，GI指的是接收环境中其他物体的光照反映。